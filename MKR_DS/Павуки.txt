Павуки — це класи, які визначають, як певний сайт (або група сайтів) буде очищено, зокрема, як виконувати сканування (тобто переходити за посиланнями) та як витягувати структуровані дані з їхніх сторінок (тобто скрейзувати елементи). Іншими словами, Spiders — це місце, де ви визначаєте користувацьку поведінку для сканування та аналізу сторінок для певного сайту (або, в деяких випадках, групи сайтів).

Для павуків цикл очищення проходить приблизно так:

-Ви починаєте з генерування початкових запитів для сканування перших URL-адрес і вказуєте функцію зворотного виклику, яка буде викликана з відповіддю, завантаженою з цих запитів.

Перші запити для виконання отримують шляхом виклику start_requests()методу, який (за замовчуванням) генерує Requestдля URL-адрес, зазначених у методі, start_urlsі parseяк функцію зворотного виклику для запитів.

-У функції зворотного виклику ви аналізуєте відповідь (веб-сторінку) і повертаєте об’єкти елемента , Requestоб’єкти або ітерацію з цих об’єктів. Ці Запити також міститимуть зворотний виклик (можливо, той самий), і потім будуть завантажені Scrapy, а потім їх відповідь оброблятиметься вказаним зворотним викликом.

-У функціях зворотного виклику ви аналізуєте вміст сторінки, як правило, за допомогою селекторів (але ви також можете використовувати BeautifulSoup, lxml або будь-який інший механізм, який вам подобається) і генеруєте елементи з розібраними даними.

-Нарешті, елементи, повернуті з павука, зазвичай зберігаються в базі даних (у деяких Item Pipeline ) або записуються у файл за допомогою Feed exports 

Незважаючи на те, що цей цикл застосовується (більш-менш) до будь-якого типу павуків, існують різні 
типи павуків за замовчуванням, які входять у Scrapy для різних цілей. Про ці типи ми поговоримо тут.

Аргументи павука
Павуки можуть отримувати аргументи, які змінюють їх поведінку. Деякі поширені варіанти використання аргументів spider — це визначення початкових URL-адрес або обмеження сканування певними розділами сайту, але їх можна використовувати для налаштування будь-яких функцій павука.

Аргументи павука передаються через crawl команду за допомогою -a параметра


Загальні павуки
Scrapy постачається з деякими корисними загальними павуками, які ви можете використовувати для підкласу ваших павуків. Їх мета — надати зручну функціональність для кількох поширених випадків скрейпінгу, як-от перехід за всіма посиланнями на сайті на основі певних правил, сканування з карт сайту або аналіз каналу XML/CSV.

CrawlSpider
Це найбільш часто використовуваний павук для сканування звичайних веб-сайтів, оскільки він забезпечує зручний механізм переходу за посиланнями, визначаючи набір правил. Можливо, він не найкраще підходить для ваших конкретних веб-сайтів або проекту, але він досить загальний для кількох випадків, тому ви можете почати з нього та замінити його за потреби для більшої користувацьких функцій або просто реалізувати власний павук.




